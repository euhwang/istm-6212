{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Word Counts\n",
    "## Part A. Characters in Little Women\n",
    "#### How many times are each of the following characters mentioned by name in the text of Little Women?\n",
    "* Jo, Beth, Meg, Amy\n",
    "\n",
    "The following cell retrieves the text file of Little Women from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 23:28:09--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1053440 (1.0M) [text/plain]\n",
      "Saving to: ‘women.txt’\n",
      "\n",
      "women.txt           100%[===================>]   1.00M  1.26MB/s    in 0.8s    \n",
      "\n",
      "2016-09-21 23:28:11 (1.26 MB/s) - ‘women.txt’ saved [1053440/1053440]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell counts the number of times each of the names (Jo, Beth, Meg, Amy) are mentioned in the text of Little Women. I made my search feature case insensitive so that \"Jo\" and \"JO\" would be seen as the same word. Then, I transformed all the words to lower case words, sorted and found the unique count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 652 amy\r\n",
      " 467 beth\r\n",
      "1362 jo\r\n",
      " 686 meg\r\n"
     ]
    }
   ],
   "source": [
    "!grep -iow \"Jo\\|Beth\\|Meg\\|Amy\" women.txt \\\n",
    "    | grep -oE '\\w{{2,}}' \\\n",
    "    | tr '[:upper:]' '[:lower:]' \\\n",
    "    | sort \\\n",
    "    | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B. Juliet and Romeo in Romeo and Juliet\n",
    "#### How many times do each of the characters Juliet and Romeo have speaking lines in Romeo and Juliet?\n",
    "\n",
    "The following cell retrieves the text file of Romeo and Juliet from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 23:28:26--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 178983 (175K) [text/plain]\n",
      "Saving to: ‘romeo.txt’\n",
      "\n",
      "romeo.txt           100%[===================>] 174.79K   523KB/s    in 0.3s    \n",
      "\n",
      "2016-09-21 23:28:27 (523 KB/s) - ‘romeo.txt’ saved [178983/178983]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell counts the number of times each of the characters, Romeo and Juliet, have speaking lines in the text of Romeo and Juliet. Since speaking lines are indicated by the first three letters of the character's name, I searched by \"Rom\" for Romeo and \"Jul\" for Juliet. Then, I sorted and found the unique count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 117 Jul\r\n",
      " 163 Rom\r\n"
     ]
    }
   ],
   "source": [
    "!grep -ow \"Rom\\|Jul\" romeo.txt \\\n",
    "    | grep -oE '\\w{{2,}}' \\\n",
    "    | sort \\\n",
    "    | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Capital Bikeshare\n",
    "## Part A\n",
    "#### Which 10 Capital Bikeshare stations were the most popular departing stations in Q1 2016? \n",
    "#### Which 10 were the most popular destination stations in Q1 2016?\n",
    "\n",
    "The following cell retrieves the zip file of Capital Bikeshare from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 23:28:34--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10643003 (10M) [application/octet-stream]\n",
      "Saving to: ‘2016q1.csv.zip’\n",
      "\n",
      "2016q1.csv.zip      100%[===================>]  10.15M  1.63MB/s    in 6.2s    \n",
      "\n",
      "2016-09-21 23:28:41 (1.62 MB/s) - ‘2016q1.csv.zip’ saved [10643003/10643003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell unzips the downloaded 2016 first quarter trip dataset from Capital Bikeshare's trip history data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  2016q1.csv.zip\n",
      "  inflating: 2016q1.csv              \n"
     ]
    }
   ],
   "source": [
    "!unzip 2016q1.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following cell shows the 10 most popular departing stations in Q1 2016. To obtain this information, I selected the start station column, then sorted and found the unique count of each station. Then I sorted by reverse order on the count and presented the top 10 most popular departing stations.\n",
    "\n",
    "Please note that this may take several minutes to run. It takes, on average, 1 minute and 44 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------------------------------------------------------------|\r\n",
      "|  13120 Columbus Circle / Union Station                     |\r\n",
      "|------------------------------------------------------------|\r\n",
      "|  9560 Massachusetts Ave & Dupont Circle NW                 |\r\n",
      "|  9388 Lincoln Memorial                                     |\r\n",
      "|  8138 Jefferson Dr & 14th St SW                            |\r\n",
      "|  7479 Thomas Circle                                        |\r\n",
      "|  7401 15th & P St NW                                       |\r\n",
      "|  6568 14th & V St NW                                       |\r\n",
      "|  6491 New Hampshire Ave & T St NW                          |\r\n",
      "|  5649 Eastern Market Metro / Pennsylvania Ave & 7th St SE  |\r\n",
      "|  5514 17th & Corcoran St NW                                |\r\n",
      "|------------------------------------------------------------|\r\n",
      "\r\n",
      "real\t1m43.843s\r\n",
      "user\t1m44.929s\r\n",
      "sys\t0m0.263s\r\n"
     ]
    }
   ],
   "source": [
    "!time csvcut -c5 2016q1.csv | csvsort -c1 | uniq -c | sort -rn | head -10 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following cell shows the 10 most popular destination stations in Q1 2016. To obtain this information, I selected the end station column, then sorted and found the unique count of each station. Then I sorted by reverse order on the count and presented the top 10 most popular destination stations.\n",
    "\n",
    "Please note that this may take several minutes to run. It takes, on average, 1 minute and 44 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------------------------------------------|\r\n",
      "|  13880 Columbus Circle / Union Station       |\r\n",
      "|----------------------------------------------|\r\n",
      "|  11183 Massachusetts Ave & Dupont Circle NW  |\r\n",
      "|  9419 Lincoln Memorial                       |\r\n",
      "|  8975 Jefferson Dr & 14th St SW              |\r\n",
      "|  8092 15th & P St NW                         |\r\n",
      "|  7267 14th & V St NW                         |\r\n",
      "|  6997 Thomas Circle                          |\r\n",
      "|  6245 New Hampshire Ave & T St NW            |\r\n",
      "|  5761 5th & K St NW                          |\r\n",
      "|  5651 17th & Corcoran St NW                  |\r\n",
      "|----------------------------------------------|\r\n",
      "\r\n",
      "real\t1m44.065s\r\n",
      "user\t1m45.111s\r\n",
      "sys\t0m0.280s\r\n"
     ]
    }
   ],
   "source": [
    "!time csvcut -c7 2016q1.csv | csvsort -c1 | uniq -c | sort -rn | head -10 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part B\n",
    "#### For the most popular departure station, which 10 bikes were used most in trips departing from there? \n",
    "#### Which 10 bikes were used most in trips ending at the most popular destination station?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell identifies the top 10 most used bikes at the most popular departing stations, which was \"Columbus Circle / Union Station\". I only looked at the Start Station and Bike Number column. I started by looking at the most popular departure station. Then I sorted on the Bike number and found the unique count for each bike number. Then I sorted by reverse order on the count and presented the top 10 most used bikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n",
      "|---------------------------------------+---------|\r\n",
      "|    17 Columbus Circle / Union Station | W22227  |\r\n",
      "|---------------------------------------+---------|\r\n",
      "|    16 Columbus Circle / Union Station | W21867  |\r\n",
      "|    16 Columbus Circle / Union Station | W21641  |\r\n",
      "|    16 Columbus Circle / Union Station | W21538  |\r\n",
      "|    16 Columbus Circle / Union Station | W21239  |\r\n",
      "|    16 Columbus Circle / Union Station | W20540  |\r\n",
      "|    16 Columbus Circle / Union Station | W00714  |\r\n",
      "|    15 Columbus Circle / Union Station | W22080  |\r\n",
      "|    15 Columbus Circle / Union Station | W21450  |\r\n",
      "|    15 Columbus Circle / Union Station | W21076  |\r\n",
      "|---------------------------------------+---------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -c5,8 2016q1.csv \\\n",
    "    | csvgrep -c1 -m 'Columbus Circle / Union Station' \\\n",
    "    | csvsort -c2 \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10 \\\n",
    "    | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell identifies the top 10 most used bikes at the most popular destinatioin stations, which was \"Columbus Circle / Union Station\". I only looked at the End Station and Bike Number column. I started by looking at the most popular destination station. Then I sorted on the Bike number and found the unique count for each bike number. Then I sorted by reverse order on the count and presented the top 10 most used bikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n",
      "|---------------------------------------+---------|\r\n",
      "|    18 Columbus Circle / Union Station | W00485  |\r\n",
      "|---------------------------------------+---------|\r\n",
      "|    17 Columbus Circle / Union Station | W22227  |\r\n",
      "|    16 Columbus Circle / Union Station | W22099  |\r\n",
      "|    16 Columbus Circle / Union Station | W22080  |\r\n",
      "|    16 Columbus Circle / Union Station | W21239  |\r\n",
      "|    16 Columbus Circle / Union Station | W21076  |\r\n",
      "|    16 Columbus Circle / Union Station | W20425  |\r\n",
      "|    16 Columbus Circle / Union Station | W00714  |\r\n",
      "|    15 Columbus Circle / Union Station | W21997  |\r\n",
      "|    15 Columbus Circle / Union Station | W21867  |\r\n",
      "|---------------------------------------+---------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -c7,8 2016q1.csv \\\n",
    "    | csvgrep -c1 -m 'Columbus Circle / Union Station' \\\n",
    "    | csvsort -c2 \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10 \\\n",
    "    | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Filters\n",
    "## Part A\n",
    "#### Demonstrate a pipeline that performs a count of the top ten unique words in Little Women. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell counts the top ten unique words in Little Women by splitting into one word per line, changing every word to lower case, sorting the list, finding the unique counts, sorting by numeric in reverse order and showing the top ten unique words.\n",
    "\n",
    "Please note that grep -oE '\\w{{1,}}' will look for all words that have one or more character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155 and\r\n",
      "7689 the\r\n",
      "5152 to\r\n",
      "4531 a\r\n",
      "4003 i\r\n",
      "3523 of\r\n",
      "3245 her\r\n",
      "2774 it\r\n",
      "2503 in\r\n",
      "2447 you\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt | grep -oE '\\w{{1,}}' | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following two cells grants all users permissions to execute the python filters: split.py and lower.py. The split.py filter splits each line of input into one word per line. The lower.py filter transforms all words to lower case words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x lower.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell counts the top ten unique words in Little Women by splitting into one word per line, changing every word to lower case, sorting the list, finding the unique counts, sorting by numeric in reverse order and showing the top ten unique words. However, the following cell uses python filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155 and\n",
      "7689 the\n",
      "5152 to\n",
      "4531 a\n",
      "4003 i\n",
      "3523 of\n",
      "3245 her\n",
      "2774 it\n",
      "2503 in\n",
      "2447 you\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt | ./split.py | ./lower.py | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part B\n",
    "#### Write a Python filter that removes at least ten common words of English text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell grants all users permissions to execute the python filters: stop.py. The stop.py filter removes stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x stop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell counts the top 25 unique words in Little Women that are not in the stop word list by changing every word to lower case, splitting into one word per line, removing the stop words, sorting the list, finding the unique counts, sorting by numeric in reverse order and showing the top 25 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343 she\r\n",
      "2233 for\r\n",
      "2033 was\r\n",
      "1978 as\r\n",
      "1854 with\r\n",
      "1598 he\r\n",
      "1469 but\r\n",
      "1362 jo\r\n",
      "1135 so\r\n",
      "1118 his\r\n",
      "1067 at\r\n",
      "1063 had\r\n",
      "1014 be\r\n",
      " 976 on\r\n",
      " 942 not\r\n",
      " 916 if\r\n",
      " 881 all\r\n",
      " 843 my\r\n",
      " 827 said\r\n",
      " 821 is\r\n",
      " 782 him\r\n",
      " 755 me\r\n",
      " 730 little\r\n",
      " 725 one\r\n",
      " 719 they\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt | ./lower.py | ./stop.py | sort | uniq -c | sort -rn | head -25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "#### Use GNU parallel to count the 25 most common words across all the 109 texts in the zip file provided, with stop words removed.\n",
    "The following cell retrieves all 109 texts in the zip file from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 23:38:14--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/texts.zip\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12668137 (12M) [application/octet-stream]\n",
      "Saving to: ‘texts.zip’\n",
      "\n",
      "texts.zip           100%[===================>]  12.08M  1.81MB/s    in 6.7s    \n",
      "\n",
      "2016-09-21 23:38:21 (1.79 MB/s) - ‘texts.zip’ saved [12668137/12668137]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/texts.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell unzips the downloaded 109 texts in the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  texts.zip\n",
      "  inflating: 10001.txt               \n",
      "  inflating: 10002.txt               \n",
      "  inflating: 10003.txt               \n",
      "  inflating: 10004.txt               \n",
      "  inflating: 10005.txt               \n",
      "  inflating: 10006.txt               \n",
      "  inflating: 10007.txt               \n",
      "  inflating: 10008.txt               \n",
      "  inflating: 10009.txt               \n",
      "  inflating: 10010.txt               \n",
      "  inflating: 10011.txt               \n",
      "  inflating: 10012.txt               \n",
      "  inflating: 10013.txt               \n",
      "  inflating: 10014.txt               \n",
      "  inflating: 10015.txt               \n",
      "  inflating: 10016.txt               \n",
      "  inflating: 10017.txt               \n",
      "  inflating: 10018.txt               \n",
      "  inflating: 10019.txt               \n",
      "  inflating: 10020.txt               \n",
      "  inflating: 10021.txt               \n",
      "  inflating: 10023.txt               \n",
      "  inflating: 10024.txt               \n",
      "  inflating: 10025.txt               \n",
      "  inflating: 10026.txt               \n",
      "  inflating: 10027.txt               \n",
      "  inflating: 10028.txt               \n",
      "  inflating: 10029.txt               \n",
      "  inflating: 10030.txt               \n",
      "  inflating: 10031.txt               \n",
      "  inflating: 10032.txt               \n",
      "  inflating: 10033.txt               \n",
      "  inflating: 10034.txt               \n",
      "  inflating: 10035.txt               \n",
      "  inflating: 10036.txt               \n",
      "  inflating: 10037.txt               \n",
      "  inflating: 10038.txt               \n",
      "  inflating: 10039.txt               \n",
      "  inflating: 10040.txt               \n",
      "  inflating: 10041.txt               \n",
      "  inflating: 10042.txt               \n",
      "  inflating: 10043.txt               \n",
      "  inflating: 10045.txt               \n",
      "  inflating: 10046.txt               \n",
      "  inflating: 10047.txt               \n",
      "  inflating: 10048.txt               \n",
      "  inflating: 10049.txt               \n",
      "  inflating: 10050.txt               \n",
      "  inflating: 10051.txt               \n",
      "  inflating: 10052.txt               \n",
      "  inflating: 10056.txt               \n",
      "  inflating: 10059.txt               \n",
      "  inflating: 10060.txt               \n",
      "  inflating: 10062.txt               \n",
      "  inflating: 12370.txt               \n",
      "  inflating: 12372.txt               \n",
      "  inflating: 12373.txt               \n",
      "  inflating: 12374.txt               \n",
      "  inflating: 12375.txt               \n",
      "  inflating: 12376.txt               \n",
      "  inflating: 12377.txt               \n",
      "  inflating: 12378.txt               \n",
      "  inflating: 12380.txt               \n",
      "  inflating: 12381.txt               \n",
      "  inflating: 12383.txt               \n",
      "  inflating: 12384.txt               \n",
      "  inflating: 12385.txt               \n",
      "  inflating: 12386.txt               \n",
      "  inflating: 1jcfs10.txt             \n",
      "  inflating: 2babb10.txt             \n",
      "  inflating: 3babb10.txt             \n",
      "  inflating: 50bab10.txt             \n",
      "  inflating: ajtl10.txt              \n",
      "  inflating: allyr10.txt             \n",
      "  inflating: alpsn10.txt             \n",
      "  inflating: balen10.txt             \n",
      "  inflating: baleng2.txt             \n",
      "  inflating: batlf10.txt             \n",
      "  inflating: bgopr10.txt             \n",
      "  inflating: brnte10.txt             \n",
      "  inflating: bstjg10.txt             \n",
      "  inflating: cambp10.txt             \n",
      "  inflating: canbe10.txt             \n",
      "  inflating: cantp10.txt             \n",
      "  inflating: cfrz10.txt              \n",
      "  inflating: crsnk10.txt             \n",
      "  inflating: esbio10.txt             \n",
      "  inflating: grybr10.txt             \n",
      "  inflating: mklmt10.txt             \n",
      "  inflating: morem10.txt             \n",
      "  inflating: mspcd10.txt             \n",
      "  inflating: penbr10.txt             \n",
      "  inflating: pgjr10.txt              \n",
      "  inflating: pntvw10.txt             \n",
      "  inflating: prcpg10.txt             \n",
      "  inflating: prhg10.txt              \n",
      "  inflating: prhsb10.txt             \n",
      "  inflating: rlsl110.txt             \n",
      "  inflating: rlsl210.txt             \n",
      "  inflating: rmlav10.txt             \n",
      "  inflating: sesli10.txt             \n",
      "  inflating: svyrd10.txt             \n",
      "  inflating: tecom10.txt             \n",
      "  inflating: utrkj10.txt             \n",
      "  inflating: vpasm10.txt             \n",
      "  inflating: wldsp10.txt             \n",
      "  inflating: wtrbs10.txt             \n",
      "  inflating: zncli10.txt             \n"
     ]
    }
   ],
   "source": [
    "!unzip texts.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell removes romeo.txt and women.txt so that it would not be counted as part of the 109 texts to find the 25 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm romeo.txt women.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses GNU parallel to look across all text files, transforms all words to lower case words and adds the words into all-words.txt file.\n",
    "\n",
    "Please note that you must have GNU parallel installed on your computer in order to run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic tradition requires you to cite works you base your article on.\n",
      "When using programs that use GNU Parallel to process data for publication\n",
      "please cite:\n",
      "\n",
      "  O. Tange (2011): GNU Parallel - The Command-Line Power Tool,\n",
      "  ;login: The USENIX Magazine, February 2011:42-47.\n",
      "\n",
      "This helps funding further development; AND IT WON'T COST YOU A CENT.\n",
      "If you pay 10000 EUR you should feel free to use GNU Parallel without citing.\n",
      "\n",
      "To silence the citation notice: run 'parallel --citation'.\n",
      "\n",
      "\n",
      "real\t0m2.466s\n",
      "user\t0m16.110s\n",
      "sys\t0m1.068s\n"
     ]
    }
   ],
   "source": [
    "!time ls *.txt \\\n",
    "    | parallel -j+0 \"grep -oE '\\w{2,}' {} | tr '[:upper:]' '[:lower:]' >> all-words.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell removes stop words, sorts the list, finds the unique counts, sorts by numeric in reverse order shows the top 25 unique words\n",
    "\n",
    "Please note that this may take several minutes to run. It takes, on average, 1 minute and 25 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55190 was\r\n",
      "53167 he\r\n",
      "47913 is\r\n",
      "47274 with\r\n",
      "43038 for\r\n",
      "42810 his\r\n",
      "41617 as\r\n",
      "33073 on\r\n",
      "32999 but\r\n",
      "32045 not\r\n",
      "31645 at\r\n",
      "31295 had\r\n",
      "30535 be\r\n",
      "28312 by\r\n",
      "27823 this\r\n",
      "26346 my\r\n",
      "25670 or\r\n",
      "25248 have\r\n",
      "25120 all\r\n",
      "23895 which\r\n",
      "23749 they\r\n",
      "23709 from\r\n",
      "21886 we\r\n",
      "20651 are\r\n",
      "19919 me\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n",
      "\r\n",
      "real\t1m23.408s\r\n",
      "user\t1m26.532s\r\n",
      "sys\t0m0.218s\r\n"
     ]
    }
   ],
   "source": [
    "!time ./stop.py all-words.txt \\\n",
    "    | sort \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
